{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation and Object Detection with pre-trained Mask RCNN model\n",
    "\n",
    "Mask RCNN networks are extensions to Faster RCNN networks.\n",
    "`gluoncv.model_zoo.MaskRCNN` is inherited from\n",
    "`gluoncv.model_zoo.FasterRCNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from gluoncv import model_zoo, data, utils\n",
    "from mxnet import image, gpu, nd, gpu\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "import numpy as np\n",
    "\n",
    "context = gpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a pretrained model\n",
    "\n",
    "\n",
    "Let's get an Mask RCNN model trained on COCO dataset with ResNet-50 backbone.\n",
    "By specifying ``pretrained=True``, it will automatically download the model\n",
    "from the model zoo if necessary.\n",
    "\n",
    "The returned model is a HybridBlock `gluoncv.model_zoo.MaskRCNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = model_zoo.get_model('mask_rcnn_resnet50_v1b_coco', ctx=context, pretrained=True)\n",
    "print(net.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process an image\n",
    "\n",
    "The pre-processing step is identical to Faster RCNN.\n",
    "\n",
    "Next we download an image, and pre-process with preset data transforms.\n",
    "The default behavior is to resize the short edge of the image to 600px.\n",
    "But you can feed an arbitrarily sized image.\n",
    "\n",
    "You can provide a list of image file names, such as ``[im_fname1, im_fname2,\n",
    "...]`` to :py:func:`gluoncv.data.transforms.presets.rcnn.load_test` if you\n",
    "want to load multiple image together.\n",
    "\n",
    "This function returns two results. The first is a NDArray with shape\n",
    "`(batch_size, RGB_channels, height, width)`. It can be fed into the\n",
    "model directly. The second one contains the images in numpy format to\n",
    "easy to be plotted. Since we only loaded a single image, the first dimension\n",
    "of `x` is 1.\n",
    "\n",
    "Please beware that `orig_img` is resized to short edge 600px.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://s3-us-west-1.amazonaws.com/s3.kllcfm.radio.com/styles/delta__775x515/s3/cutch.jpg?itok=peJK9kV-&c=bde29864317af570bf02f494b8a414c9'\n",
    "filename = 'example.jpg'\n",
    "utils.download(url, filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.imread(filename)\n",
    "plt.imshow(img.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, orig_img = data.transforms.presets.rcnn.load_test(filename)\n",
    "x = x.as_in_context(context)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and display\n",
    "\n",
    "The Mask RCNN model returns predicted class IDs, confidence scores,\n",
    "bounding boxes coordinates and segmentation masks.\n",
    "Their shape are (batch_size, num_bboxes, 1), (batch_size, num_bboxes, 1)\n",
    "(batch_size, num_bboxes, 4), and (batch_size, num_bboxes, mask_size, mask_size)\n",
    "respectively. For the model used in this tutorial, mask_size is 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, scores, bboxes, masks = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids    = ids[0].asnumpy()\n",
    "scores = scores[0].asnumpy()\n",
    "bboxes = bboxes[0].asnumpy()\n",
    "masks  = masks[0].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten scores\n",
    "score_list = scores.reshape(-1)\n",
    "# Print scores\n",
    "score_list = score_list[np.where (score_list != -1)])\n",
    "print(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 scores\n",
    "print(score_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation\n",
    "\n",
    "`gluoncv.utils.viz.expand_mask` will resize the segmentation mask\n",
    "and fill the bounding box size in the original image.\n",
    "`gluoncv.utils.viz.plot_mask` will modify an image to\n",
    "overlay segmentation masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = orig_img.shape[1], orig_img.shape[0]\n",
    "masks = utils.viz.expand_mask(masks, bboxes, (width, height), scores, thresh=0.68)\n",
    "orig_img = utils.viz.plot_mask(orig_img, masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection\n",
    "\n",
    "We can use `gluoncv.utils.viz.plot_bbox` to visualize the\n",
    "results. We slice the results for the first image and feed them into `plot_bbox`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identical to Faster RCNN object detection\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax = utils.viz.plot_bbox(orig_img, bboxes, scores, ids, class_names=net.classes, ax=ax, thresh=0.68)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
