# Scikit-learn Examples

[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.0+-orange.svg)](https://scikit-learn.org/)
[![XGBoost](https://img.shields.io/badge/XGBoost-1.5+-green.svg)](https://xgboost.readthedocs.io/)
[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://python.org/)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org/)
[![NumPy](https://img.shields.io/badge/NumPy-1.20+-blue.svg)](https://numpy.org/)
[![Pandas](https://img.shields.io/badge/Pandas-1.3+-blue.svg)](https://pandas.pydata.org/)
[![Archived](https://img.shields.io/badge/status-archived-red.svg)](https://github.com/julsimon/dlnotebooks)

> **‚ö†Ô∏è This folder is part of an archived repository.**

Comprehensive examples demonstrating traditional machine learning techniques using scikit-learn, from basic linear models to advanced ensemble methods.

## üìÅ Contents

### Supervised Learning
- **01 - Linear Regression.ipynb**: Linear regression fundamentals
- **02 - Logistic Regression.ipynb**: Logistic regression for classification
- **02a - Logistic Regression on MNIST.ipynb**: MNIST digit classification
- **03 - Decision Trees.ipynb**: Decision tree algorithms
- **03a - Random Forest.ipynb**: Random forest ensemble method
- **03b - XGBoost.ipynb**: Gradient boosting with XGBoost

### Unsupervised Learning
- **04 - K-means.ipynb**: K-means clustering algorithm
- **05 - PCA.ipynb**: Principal Component Analysis
- **05a - PCA + Logistic Regression on MNIST.ipynb**: Dimensionality reduction with classification

## üöÄ Quick Start

### Prerequisites

```bash
pip install scikit-learn xgboost numpy pandas matplotlib jupyter
```

### Running the Examples

1. **Beginner**: Start with `01 - Linear Regression.ipynb`
2. **Classification**: Try `02 - Logistic Regression.ipynb`
3. **Ensemble Methods**: Explore `03a - Random Forest.ipynb`
4. **Advanced**: Check `03b - XGBoost.ipynb`

## üìñ What You'll Learn

- Linear and logistic regression
- Decision trees and ensemble methods
- Random forests and gradient boosting
- K-means clustering
- Principal Component Analysis (PCA)
- Feature engineering and selection
- Model evaluation and validation
- MNIST digit classification

## üîó Resources

- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [MNIST Dataset](http://yann.lecun.com/exdb/mnist/)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html) 