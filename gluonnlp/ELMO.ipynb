{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU gluonnlp awscli botocore boto3 nltk sacremoses --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import random\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import gluonnlp as nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "We first show that they can be easily added to existing models for six diverse and challenging language understanding problems, including textual entailment, question answering and sentiment analysis.\n"
     ]
    }
   ],
   "source": [
    "elmo_intro = \"\"\"\n",
    "Extensive experiments demonstrate that ELMo representations work extremely well in practice.\n",
    "We first show that they can be easily added to existing models for six diverse and challenging language understanding problems, including textual entailment, question answering and sentiment analysis.\n",
    "The addition of ELMo representations alone significantly improves the state of the art in every case, including up to 20% relative error reductions.\n",
    "For tasks where direct comparisons are possible, ELMo outperforms CoVe (McCann et al., 2017), which computes contextualized representations using a neural machine translation encoder.\n",
    "Finally, an analysis of both ELMo and CoVe reveals that deep representations outperform those derived from just the top layer of an LSTM.\n",
    "Our trained models and code are publicly available, and we expect that ELMo will provide similar gains for many other NLP problems.\n",
    "\"\"\"\n",
    "\n",
    "elmo_intro_file = 'elmo_intro.txt'\n",
    "with io.open(elmo_intro_file, 'w', encoding='utf8') as f:\n",
    "    f.write(elmo_intro)\n",
    "\n",
    "dataset = nlp.data.TextLineDataset(elmo_intro_file, 'utf8')\n",
    "print(len(dataset))\n",
    "print(dataset[2]) # print an example sentence from the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<bos>', 'We', 'first', 'show', 'that', 'they', 'can', 'be', 'easily', 'added', 'to', 'existing', 'models', 'for', 'six', 'diverse', 'and', 'challenging', 'language', 'understanding', 'problems', ',', 'including', 'textual', 'entailment', ',', 'question', 'answering', 'and', 'sentiment', 'analysis', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nlp.data.SacreMosesTokenizer()\n",
    "dataset = dataset.transform(tokenizer)\n",
    "dataset = dataset.transform(lambda x: ['<bos>'] + x + ['<eos>'])\n",
    "print(dataset[2]) # print the same tokenized sentence as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's transform each word into a series of tokens. \n",
    "\n",
    "0-255 values come from UTF-8, and some tokens have a special meaning:\n",
    "  * bos_id (256) – The index of beginning of the sentence character\n",
    "  * eos_id (257) – The index of end of the sentence character\n",
    "  * bow_id (258) – The index of beginning of the word character\n",
    "  * eow_id (259) – The index of end of the word character\n",
    "  * pad_id (260) – The index of padding character is 260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = nlp.vocab.ELMoCharVocab()\n",
    "dataset = dataset.transform(lambda x: (vocab[x], len(x)), lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[258, 256, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 87, 101, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 102, 105, 114, 115, 116, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 115, 104, 111, 119, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 116, 104, 97, 116, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 116, 104, 101, 121, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 99, 97, 110, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 98, 101, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 101, 97, 115, 105, 108, 121, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 97, 100, 100, 101, 100, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 116, 111, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 101, 120, 105, 115, 116, 105, 110, 103, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 109, 111, 100, 101, 108, 115, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 102, 111, 114, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 115, 105, 120, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 100, 105, 118, 101, 114, 115, 101, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 97, 110, 100, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 99, 104, 97, 108, 108, 101, 110, 103, 105, 110, 103, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 108, 97, 110, 103, 117, 97, 103, 101, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 117, 110, 100, 101, 114, 115, 116, 97, 110, 100, 105, 110, 103, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 112, 114, 111, 98, 108, 101, 109, 115, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 44, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 105, 110, 99, 108, 117, 100, 105, 110, 103, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 116, 101, 120, 116, 117, 97, 108, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 101, 110, 116, 97, 105, 108, 109, 101, 110, 116, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 44, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 113, 117, 101, 115, 116, 105, 111, 110, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 97, 110, 115, 119, 101, 114, 105, 110, 103, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 97, 110, 100, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 115, 101, 110, 116, 105, 109, 101, 110, 116, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 97, 110, 97, 108, 121, 115, 105, 115, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 46, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260], [258, 257, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260]], 33)\n"
     ]
    }
   ],
   "source": [
    "print(dataset[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonnlp/data/batchify/batchify.py:228: UserWarning: Padding value is not given and will be set automatically to 0 in data.batchify.Pad(). Please check whether this is intended (e.g. value of padding index in the vocabulary).\n",
      "  'Padding value is not given and will be set automatically to 0 '\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "dataset_batchify_fn = nlp.data.batchify.Tuple(nlp.data.batchify.Pad(),\n",
    "                                              nlp.data.batchify.Stack())\n",
    "data_loader = gluon.data.DataLoader(dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    batchify_fn=dataset_batchify_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/ec2-user/.mxnet/models/elmo_2x1024_128_2048cnn_1xhighway_gbw-8c9257d9.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/elmo_2x1024_128_2048cnn_1xhighway_gbw-8c9257d9.zip...\n",
      "ELMoBiLM(\n",
      "  (_elmo_char_encoder): ELMoCharacterEncoder(\n",
      "    (_char_embedding): Embedding(262 -> 16, float32)\n",
      "    (_convolutions): ConvolutionalEncoder(\n",
      "      (_convs): HybridConcurrent(\n",
      "        (0): HybridSequential(\n",
      "          (0): Conv1D(16 -> 32, kernel_size=(1,), stride=(1,))\n",
      "          (1): HybridLambda(<lambda>)\n",
      "          (2): Activation(relu)\n",
      "        )\n",
      "        (1): HybridSequential(\n",
      "          (0): Conv1D(16 -> 32, kernel_size=(2,), stride=(1,))\n",
      "          (1): HybridLambda(<lambda>)\n",
      "          (2): Activation(relu)\n",
      "        )\n",
      "        (2): HybridSequential(\n",
      "          (0): Conv1D(16 -> 64, kernel_size=(3,), stride=(1,))\n",
      "          (1): HybridLambda(<lambda>)\n",
      "          (2): Activation(relu)\n",
      "        )\n",
      "        (3): HybridSequential(\n",
      "          (0): Conv1D(16 -> 128, kernel_size=(4,), stride=(1,))\n",
      "          (1): HybridLambda(<lambda>)\n",
      "          (2): Activation(relu)\n",
      "        )\n",
      "        (4): HybridSequential(\n",
      "          (0): Conv1D(16 -> 256, kernel_size=(5,), stride=(1,))\n",
      "          (1): HybridLambda(<lambda>)\n",
      "          (2): Activation(relu)\n",
      "        )\n",
      "        (5): HybridSequential(\n",
      "          (0): Conv1D(16 -> 512, kernel_size=(6,), stride=(1,))\n",
      "          (1): HybridLambda(<lambda>)\n",
      "          (2): Activation(relu)\n",
      "        )\n",
      "        (6): HybridSequential(\n",
      "          (0): Conv1D(16 -> 1024, kernel_size=(7,), stride=(1,))\n",
      "          (1): HybridLambda(<lambda>)\n",
      "          (2): Activation(relu)\n",
      "        )\n",
      "      )\n",
      "      (_highways): Highway(\n",
      "        (hnet): HybridSequential(\n",
      "          (0): Dense(2048 -> 4096, linear)\n",
      "        )\n",
      "        (_activation): Activation(relu)\n",
      "      )\n",
      "      (_projection): Dense(2048 -> 128, linear)\n",
      "    )\n",
      "  )\n",
      "  (_elmo_lstm): BiLMEncoder(\n",
      "    (forward_layers): HybridSequentialRNNCell(\n",
      "    (0): HybridSequentialRNNCell(\n",
      "      (0): LSTMPCellWithClip(128 -> 4096 -> 128)\n",
      "      )\n",
      "    (1): HybridSequentialRNNCell(\n",
      "      (0): ResidualCell(LSTMPCellWithClip(128 -> 4096 -> 128))\n",
      "      )\n",
      "    )\n",
      "    (backward_layers): HybridSequentialRNNCell(\n",
      "    (0): HybridSequentialRNNCell(\n",
      "      (0): LSTMPCellWithClip(128 -> 4096 -> 128)\n",
      "      )\n",
      "    (1): HybridSequentialRNNCell(\n",
      "      (0): ResidualCell(LSTMPCellWithClip(128 -> 4096 -> 128))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "elmo_bilm, _ = nlp.model.get_model('elmo_2x1024_128_2048cnn_1xhighway',\n",
    "                                   dataset_name='gbw',\n",
    "                                   pretrained=True,\n",
    "                                   ctx=mx.cpu())\n",
    "print(elmo_bilm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 14, 256), (2, 14, 256), (2, 14, 256)]\n"
     ]
    }
   ],
   "source": [
    "def get_features(data, valid_lengths):\n",
    "    length = data.shape[1]\n",
    "    hidden_state = elmo_bilm.begin_state(mx.nd.zeros, batch_size=batch_size)\n",
    "    mask = mx.nd.arange(length).expand_dims(0).broadcast_axes(axis=(0,), size=(batch_size,))\n",
    "    mask = mask < valid_lengths.expand_dims(1).astype('float32')\n",
    "    output, hidden_state = elmo_bilm(data, hidden_state, mask)\n",
    "    return output\n",
    "\n",
    "batch = next(iter(data_loader))\n",
    "features = get_features(*batch)\n",
    "print([x.shape for x in features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
