{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -qU tensorflow_hub sacremoses --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacremoses import MosesTokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Needed because I use TF 2.0\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Grab from TF hub\n",
    "#elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)\n",
    "\n",
    "# Or download and extract \n",
    "# wget \"https://tfhub.dev/google/elmo/2?tf-hub-format=compressed\" -O elmo.tar.gz\n",
    "# tar xvfz elmo.tar.gz -C elmo\n",
    "\n",
    "elmo = hub.Module(\"elmo/\", trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_intro = \"\"\"\n",
    "Extensive experiments demonstrate that ELMo representations work extremely well in practice.\n",
    "We first show that they can be easily added to existing models for six diverse and challenging language understanding problems, including textual entailment, question answering and sentiment analysis.\n",
    "The addition of ELMo representations alone significantly improves the state of the art in every case, including up to 20% relative error reductions.\n",
    "For tasks where direct comparisons are possible, ELMo outperforms CoVe (McCann et al, 2017), which computes contextualized representations using a neural machine translation encoder.\n",
    "Finally, an analysis of both ELMo and CoVe reveals that deep representations outperform those derived from just the top layer of an LSTM.\n",
    "Our trained models and code are publicly available, and we expect that ELMo will provide similar gains for many other NLP problems.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    mt = MosesTokenizer(lang='en')\n",
    "    tokens = mt.tokenize(text, return_str=True)               # tokenize text\n",
    "    tokens = tokens.split('.')                                # --> array of sentences\n",
    "    \n",
    "    tokens = [ x.split(' ') for x in tokens]                  # --> array of arrays of tokens\n",
    "    tokens = [ [y for y in x if y!=''] for x in tokens]       # remove any empty token\n",
    "    tokens = [ x for x in tokens if x!=[] ]                   # remove any empty array\n",
    "    \n",
    "    tokens_length = [len(x) for x in tokens]                  # compute array lengths\n",
    "    max_len = max(tokens_length)                              # find longest array\n",
    "    tokens = [ x + [''] * (max_len - len(x)) for x in tokens] # pad other arrays\n",
    "    tokens_length = [len(x) for x in tokens]                  # compute array lengths again\n",
    "\n",
    "    return tokens, tokens_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, tokens_length = preprocess(elmo_intro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x,y) in zip(tokens,tokens_length):\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_elmo(tokens, tokens_length):\n",
    "    embeddings = elmo(\n",
    "        inputs={\n",
    "            \"tokens\": tokens,\n",
    "            \"sequence_len\": tokens_length\n",
    "        },\n",
    "        signature=\"tokens\",\n",
    "        as_dict=True)[\"elmo\"]\n",
    "    \n",
    "    # tf.compat.v1 is needed because I use TF 2.0\n",
    "    with tf.compat.v1.Session() as session:\n",
    "        session.run([tf.compat.v1.global_variables_initializer(), \n",
    "                     tf.compat.v1.tables_initializer()])\n",
    "        elmo_embeddings = session.run(embeddings)\n",
    "    return elmo_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_embeddings = do_elmo(tokens, tokens_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print embeddings for the first word of the first sentence\n",
    "print(elmo_embeddings[0][0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silly_text = \"\"\"\n",
    "Kevin, stop throwing rocks at my car. \n",
    "This is totally stupid. \n",
    "Now, lets talk about more interesting things. \n",
    "Did you know that machine learning rocks? \n",
    "It is totally awesome!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, tokens_length = preprocess(silly_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_embeddings = do_elmo(tokens, tokens_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'rocks' in the first sentence : [0][3]\n",
    "rocks1 = elmo_embeddings[0][3]\n",
    "# 'rocks' in the fourth sentence : [3][6]\n",
    "rocks2 = elmo_embeddings[3][6]\n",
    "\n",
    "print(rocks1) \n",
    "print(rocks2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the cosine similarity of these two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.dot(rocks1, rocks2) / (np.linalg.norm(rocks1)*np.linalg.norm(rocks2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
