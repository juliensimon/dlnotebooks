{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -qU gluonnlp mxnet awscli botocore boto3 nltk sacremoses --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import random\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import gluonnlp as nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_intro = \"\"\"\n",
    "Extensive experiments demonstrate that ELMo representations work extremely well in practice.\n",
    "We first show that they can be easily added to existing models for six diverse and challenging language understanding problems, including textual entailment, question answering and sentiment analysis.\n",
    "The addition of ELMo representations alone significantly improves the state of the art in every case, including up to 20% relative error reductions.\n",
    "For tasks where direct comparisons are possible, ELMo outperforms CoVe (McCann et al., 2017), which computes contextualized representations using a neural machine translation encoder.\n",
    "Finally, an analysis of both ELMo and CoVe reveals that deep representations outperform those derived from just the top layer of an LSTM.\n",
    "Our trained models and code are publicly available, and we expect that ELMo will provide similar gains for many other NLP problems.\n",
    "\"\"\"\n",
    "\n",
    "elmo_intro_file = 'elmo_intro.txt'\n",
    "with io.open(elmo_intro_file, 'w', encoding='utf8') as f:\n",
    "    f.write(elmo_intro)\n",
    "\n",
    "dataset = nlp.data.TextLineDataset(elmo_intro_file, 'utf8')\n",
    "print(len(dataset))\n",
    "print(dataset[2]) # print an example sentence from the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nlp.data.SacreMosesTokenizer()\n",
    "dataset = dataset.transform(tokenizer)\n",
    "dataset = dataset.transform(lambda x: ['<bos>'] + x + ['<eos>'])\n",
    "print(dataset[2]) # print the same tokenized sentence as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's transform each *word* into a series of character tokens. \n",
    "\n",
    "0-255 values come from UTF-8, and some tokens have a special meaning:\n",
    "  * bos_id (256) – The index of beginning of the sentence character\n",
    "  * eos_id (257) – The index of end of the sentence character\n",
    "  * bow_id (258) – The index of beginning of the word character\n",
    "  * eow_id (259) – The index of end of the word character\n",
    "  * pad_id (260) – The index of padding character is 260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = nlp.vocab.ELMoCharVocab()\n",
    "dataset = dataset.transform(lambda x: (vocab[x], len(x)), lazy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the same sentence : an array of arrays (33, corresponding to the number of tokens). \n",
    "Each sub-array encodes a single word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "dataset_batchify_fn = nlp.data.batchify.Tuple(nlp.data.batchify.Pad(),\n",
    "                                              nlp.data.batchify.Stack())\n",
    "data_loader = gluon.data.DataLoader(dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    batchify_fn=dataset_batchify_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_bilm, _ = nlp.model.get_model('elmo_2x1024_128_2048cnn_1xhighway',\n",
    "                                   dataset_name='gbw',\n",
    "                                   pretrained=True,\n",
    "                                   ctx=mx.cpu())\n",
    "print(elmo_bilm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data, valid_lengths):\n",
    "    length = data.shape[1]\n",
    "    hidden_state = elmo_bilm.begin_state(mx.nd.zeros, batch_size=batch_size)\n",
    "    mask = mx.nd.arange(length).expand_dims(0).broadcast_axes(axis=(0,), size=(batch_size,))\n",
    "    mask = mask < valid_lengths.expand_dims(1).astype('float32')\n",
    "    output, hidden_state = elmo_bilm(data, hidden_state, mask)\n",
    "    return output\n",
    "\n",
    "batch = next(iter(data_loader))\n",
    "features = get_features(*batch)\n",
    "print([x.shape for x in features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get three outputs: one for the character-level CNN, and one for each of the two LSTMs. \n",
    "\n",
    "Each output stores:\n",
    "  * the batch size,\n",
    "  * the number of tokens for the longest sentence (other embeddings are padded to that length),\n",
    "  * the embeddings for each sentence\n",
    "  \n",
    "Let's print the LSTM outputs for the sentence above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features[1][2])\n",
    "print(features[2][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
